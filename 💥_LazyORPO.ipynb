{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jslinuxta/Colab/blob/main/%F0%9F%92%A5_LazyORPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # üí• LazyORPO\n",
        "\n",
        "# @markdown üîÑ Replaces `SFT+DPO/PPO` with `1` single method `ORPO`.\n",
        "\n",
        "# @markdown üèÜ ORPO Outperforms `SFT, SFT+DPO` on `PHI-2, Llama 2, and Mistral`\n",
        "\n",
        "# @markdown üìä Mistral ORPO achieves `12.20%` on AlpacaEval2.0, `66.19%` on IFEval, and 7.32 on MT-Bench Zephyr Beta\n",
        "\n",
        "# @markdown üîÆ Created by [@zainulabideen](https://huggingface.co/abideen).\n",
        "\n",
        "# @markdown üî¨ Based on [ORPO paper](https://huggingface.co/papers/2403.07691)\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown ### ü§ó Training Parameters\n",
        "\n",
        "!pip install -qqq runpod --progress-bar off\n",
        "\n",
        "\n",
        "import runpod\n",
        "\n",
        "MODEL_ID = \"microsoft/phi-2\" # @param {type:\"string\"}\n",
        "NEW_MODEL = \"abideen/phi2-pro\"\n",
        "DATASET = \"argilla/dpo-mix-7k\" # @param {type:\"string\"}\n",
        "EPOCH = 1 # @param {type:\"integer\"}\n",
        "LEARNING_RATE = 5e-6 # @param {type:\"number\"}\n",
        "USERNAME=\"abideen\" # @param {type:\"string\"}\n",
        "WANDB_PROJECT=\"phi2-mix\" # @param {type:\"string\"}\n",
        "HF_TOKEN=\"\" # @param {type:\"string\"}\n",
        "WANDB_TOKEN=\"\" # @param {type:\"string\"}\n",
        "OUTPUT = \"checkpoints/\"+ DATASET.split(\"/\")[-1]\n",
        "GPU = \"NVIDIA A40\" # @param [\"NVIDIA A100 80GB PCIe\", \"NVIDIA A100-SXM4-80GB\", \"NVIDIA A30\", \"NVIDIA A40\", \"NVIDIA GeForce RTX 3070\", \"NVIDIA GeForce RTX 3080\", \"NVIDIA GeForce RTX 3080 Ti\", \"NVIDIA GeForce RTX 3090\", \"NVIDIA GeForce RTX 3090 Ti\", \"NVIDIA GeForce RTX 4070 Ti\", \"NVIDIA GeForce RTX 4080\", \"NVIDIA GeForce RTX 4090\", \"NVIDIA H100 80GB HBM3\", \"NVIDIA H100 PCIe\", \"NVIDIA L4\", \"NVIDIA L40\", \"NVIDIA RTX 4000 Ada Generation\", \"NVIDIA RTX 4000 SFF Ada Generation\", \"NVIDIA RTX 5000 Ada Generation\", \"NVIDIA RTX 6000 Ada Generation\", \"NVIDIA RTX A2000\", \"NVIDIA RTX A4000\", \"NVIDIA RTX A4500\", \"NVIDIA RTX A5000\", \"NVIDIA RTX A6000\", \"Tesla V100-FHHL-16GB\", \"Tesla V100-PCIE-16GB\", \"Tesla V100-SXM2-16GB\", \"Tesla V100-SXM2-32GB\"]\n",
        "NUMBER_OF_GPUS = 1 # @param {type:\"slider\", min:1, max:8, step:1}\n",
        "CONTAINER_DISK = 500 # @param {type:\"slider\", min:50, max:500, step:25}\n",
        "VOLUME_STORAGE = 500 # @param {type:\"slider\", min:50, max:500, step:25}\n",
        "CLOUD_TYPE = \"SECURE\" # @param [\"COMMUNITY\", \"SECURE\"]\n",
        "REPO = \"https://github.com/abideenml/AutoOPRO.git\" # @param {type:\"string\"}\n",
        "TRUST_REMOTE_CODE = False # @param {type:\"boolean\"}\n",
        "\n",
        "RUNPOD_TOKEN = \"\" # @param {type:\"string\"}\n",
        "runpod.api_key = RUNPOD_TOKEN\n",
        "\n",
        "pod = runpod.create_pod(\n",
        "    name=f\"ORPO POD: {MODEL_ID.split('/')[-1]}\",\n",
        "    image_name=\"runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel-ubuntu22.04\",\n",
        "    gpu_type_id=GPU,\n",
        "    cloud_type=CLOUD_TYPE,\n",
        "    gpu_count=NUMBER_OF_GPUS,\n",
        "    volume_in_gb=VOLUME_STORAGE,\n",
        "    container_disk_in_gb=CONTAINER_DISK,\n",
        "    template_id=\"au6nz6emhk\",\n",
        "    env={\n",
        "        \"MODEL_ID\": MODEL_ID,\n",
        "        \"DATASET\": DATASET,\n",
        "        \"EPOCH\": EPOCH,\n",
        "        \"NEW_MODEL\": NEW_MODEL,\n",
        "        \"LEARNING_RATE\": LEARNING_RATE,\n",
        "        \"OUTPUT\": OUTPUT,\n",
        "        \"USERNAME\": USERNAME,\n",
        "        \"WANDB_TOKEN\": WANDB_TOKEN,\n",
        "        \"WANDB_PROJECT\": WANDB_PROJECT,\n",
        "        \"TOKEN\": HF_TOKEN,\n",
        "        \"REPO\": REPO,\n",
        "        \"TRUST_REMOTE_CODE\": TRUST_REMOTE_CODE,\n",
        "    }\n",
        ")\n",
        "print(\"Pod started: https://www.runpod.io/console/pods\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rMRTKgSx28-C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}